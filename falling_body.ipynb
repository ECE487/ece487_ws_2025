{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Galilei's Falling Body Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A note on this document**\n",
    "This document is known as a Jupyter notebook; it allows text and executable code to coexist in a very easy-to-read format. Blocks can contain text or executable code. For blocks containing code, press `Shift + Enter`, `Ctrl+Enter`, or click the arrow on the block to run the code. Earlier blocks of code need to be run for the later blocks of code to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the measurements, $y(t_0),y(t_1),\\cdots,y(t_n)$, measured at $t_0,t_1,\\cdots,t_n$, we want to find (estimate) $\\mathbf{x} = [a \\quad b \\quad c]^\\top$  that minimizes $||\\mathbf{y} - \\hat{\\mathbf{y}}||^2$ where $\\hat{y} = ax^2+bx+c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "y0 = 60\n",
    "v0 = 20\n",
    "g = -9.8067\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./data/falling_body.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the Data Frame data into numpy arrays:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data[\"time\"].to_numpy()\n",
    "y = data[\"y\"].to_numpy()\n",
    "print(t)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(t, y, \"o\")\n",
    "plt.xlabel(\"time, sec\")\n",
    "plt.ylabel(\"height (y), m\", rotation=90)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `np.polyfit` to find the best polynomial function fit.\n",
    "If our model is $\\hat{y} = at + b$, we want to use a first-order polynomial function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.polyfit(t, y, 1)\n",
    "print(coeffs)  # the first element is the slope and the second is the y-intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element in the `coeffs` array represents the slope denoted as $a$, while the second element corresponds to the $y$-intercept labeled as $b$. Employing the `np.poly1d()` function enables us to generate a polynomial function with the coefficients of our preference. To illustrate:\n",
    "\n",
    "```python\n",
    "f = np.poly1d(c)\n",
    "```\n",
    "\n",
    "This code snippet generates a function $f = c_0x^n + c_1x^{n-1} + \\cdots + c_{n-1}x + c_n$ with coefficients encapsulated within the vector $\\mathbf{c}$.\n",
    "\n",
    "In our specific scenario, using `np.poly1d(coeffs)` furnishes us with $y(t)$. Consequently, by supplying $t$ to the $y(t)$ function through `np.poly1d(coeffs)(t)`, denoted as `y(t) = np.poly1d(coeffs)(t)`, we achieve the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.poly1d(coeffs)(t)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "plt.plot(t, y, \"o\")  # plot the measured data\n",
    "plt.plot(t, y_hat, \"-\")  # plot the fitted line\n",
    "plt.xlabel(\"time, sec\")\n",
    "plt.ylabel(\"height (y), m\", rotation=90)\n",
    "plt.grid(True)\n",
    "\n",
    "ax.text(2, 40, \"M=1\", style=\"italic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line doesn't align well with the measurements. Let's examine the discrepancies (residuals) and the root mean squared error (RMSE). The residual (error) is calculated as $y-\\hat{y}$. The RMSE is then computed using the following formula:\n",
    "\n",
    "$ RMSE = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=0}(y_i-\\hat{y}_i)^2}$\n",
    "\n",
    "In the realm of linear algebra, the norm of a vector is defined as:\n",
    "\n",
    "$||\\mathbf{v}|| = \\sqrt{\\sum^{n}_{i=0}v^2_i}$\n",
    "\n",
    "Consequently, we can express the RMSE using the vector norm as:\n",
    "\n",
    "$ RMSE = \\frac{1}{\\sqrt{n}}||\\mathbf{v}|| $\n",
    "\n",
    "Here is how we can find the RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.linalg.norm(y - y_hat) / np.sqrt(len(t))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now experiment with a quadratic function for our model, represented as $\\hat{y} = at^2 + bt+c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.polyfit(t, y, 2) # 2nd order polynomial fit.\n",
    "print(coeffs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.poly1d(coeffs)(t)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "plt.plot(t, y, \"o\")  # plot the measured data\n",
    "plt.plot(t, y_hat, \"-\")  # plot the fitted line\n",
    "plt.xlabel(\"time, sec\")\n",
    "plt.ylabel(\"height (y), m\", rotation=90)\n",
    "plt.grid(True)\n",
    "\n",
    "ax.text(2, 40, \"M=2\", style=\"italic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.linalg.norm(y - y_hat) / np.sqrt(len(t))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quadratic model exhibits a significantly lower RMSE compared to the first-order model.  Let's now try with a forth-order polynomial function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.polyfit(t, y, 4) # 4th order polynomial fit\n",
    "print(coeffs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.poly1d(coeffs)(t)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "plt.plot(t, y, \"o\")  # plot the measured data\n",
    "plt.plot(t, y_hat, \"-\")  # plot the fitted line\n",
    "plt.xlabel(\"time, sec\")\n",
    "plt.ylabel(\"height (y), m\", rotation=90)\n",
    "plt.grid(True)\n",
    "\n",
    "ax.text(2, 40, \"M=4\", style=\"italic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.linalg.norm(y - y_hat) / np.sqrt(len(t))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth-order polynomial function demonstrates a slightly reduced RMSE in comparison to the second-order model. We'll delve deeper into fitting models of higher orders and address concerns related to overfitting.\n",
    "\n",
    "Moving forward, let's address the problem using the least square estimate method. We need to formulate a system of linear equations as follow\n",
    "\n",
    "$\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}  = \\begin{bmatrix} t^2_1 & t_1 & 1 \\\\ t^2_2 & t_2 & 1 \\\\ \\vdots & \\vdots & \\vdots \\\\ t^2_n & t_n & 1 \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\c \\end{bmatrix}\n",
    "$\n",
    "\n",
    "or $\\mathbf{y} = C\\mathbf{q}$ where\n",
    "\n",
    "$\\mathbf{y} = [y_1 \\quad y_2 \\quad \\cdots \\quad y_n]^\\top$,  $\\mathbf{q} = [a \\quad b \\quad c]^\\top$, and  $C = \\begin{bmatrix} t^2_1 & t_1 & 1 \\\\ t^2_2 & t_2 & 1 \\\\ \\vdots & \\vdots & \\vdots \\\\ t^2_n & t_n & 1 \\end{bmatrix} $\n",
    "\n",
    "We can formulate $C$ using `np.vstack()`. Make sure $C$ is an $n \\times 3$ matrix, i.e., $C\\in\\mathbb{R}^{n\\times 3}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.vstack([t**2, t, np.ones_like(t)]).T\n",
    "print(C.shape)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The psedu-inverse of the matrix, $C$ is given by $\\tilde{C} = (C^{\\top}C)^{-1}C^{\\top}$.  In Python, we can use `np.linalg.pinv()` to find it.  The dimension should be 3 by $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinvC = np.linalg.pinv(C)\n",
    "print(pinvC.shape)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find $\\mathbf{q} = [a \\quad b \\quad c]^\\top$:\n",
    "\n",
    "$\\mathbf{q} = \\tilde{C}\\mathbf{y} = (C^{\\top}C)^{-1}C^{\\top}\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pinvC @ y\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in xhat match the coefficients of the quadratic model obtained through the `np.polyfit` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.poly1d(q)(t)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "plt.plot(t, y, \"o\")  # plot the measured data\n",
    "plt.plot(t, y_hat, \"-\")  # plot the fitted line\n",
    "plt.xlabel(\"time, sec\")\n",
    "plt.ylabel(\"height (y), m\", rotation=90)\n",
    "plt.grid(True)\n",
    "\n",
    "ax.text(2, 40, \"M=2\", style=\"italic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to utilize the `np.linalg.lstsq` function to compute the least square estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.linalg.lstsq(C, y, rcond=None)[0]\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.linalg.lstsq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
