{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes and SVM \n",
    "\n",
    "- Author: Stan Baek  \n",
    "- Department of Electrical & Computer Engineering\n",
    "- United States Air Force Academy\n",
    "- Date: Aug 08, 2023  \n",
    "\n",
    "*2024-11-24: Comments heavily revised by Stan Baek*\n",
    "\n",
    "## Simplified BSD License (FreeBSD License)\n",
    "**Copyright (c) 2023, Stan Baek, All rights reserved.**\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "1. Redistributions of source code must retain the above copyright notice, this list of conditions, and the following disclaimer.\n",
    "2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions, and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "\n",
    "**THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.**\n",
    "\n",
    "The views and conclusions contained in the software and documentation are those of the authors and should not be interpreted as representing official policies, either expressed or implied, of the FreeBSD Project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A note on this document**\n",
    "This document is known as a Jupyter notebook; it allows text and executable code to coexist in a very easy-to-read format. Blocks can contain text or executable code. For blocks containing code, press `Shift + Enter`, `Ctrl+Enter`, or click the arrow on the block to run the code. Earlier blocks of code need to be run for the later blocks of code to work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Flowers\n",
    "\n",
    "In classification problems, the output space consists of a set of $C$ labels, which are referred to as `classes`. These labels form a set denoted as $\\mathcal{Y} = \\{1, 2, \\ldots, C\\}$. The goal in such problem is to predict the correct label for a given input, a task widely known as `pattern recognition`. \n",
    "\n",
    "In cases where there are only two possible classes, the labels are typically represented as $y \\in \\{0, 1\\}$ or  $y \\in \\{-1, +1\\}$. This specific type of classification is called binary classification.\n",
    "\n",
    "As an example of a classification task, consider classifying Iris flowers into one of three subspecies: Setosa, Versicolor, and Virginica. The image below illustrates an example from each class.\n",
    "\n",
    "<div> <img src=\"./data/iris.png\" width=\"600\"/> </div> \n",
    "Three types of Iris flowers: Setosa (left), Versicolor (center), and Virginica (right).\n",
    "\n",
    "The features in the Iris dataset are: sepal length, sepal width, petal length, and petal width. These features are used to classify the flowers into one of three subspecies: Setosa, Versicolor, or Virginica.\n",
    "\n",
    "The following code demonstrates how to load the Iris dataset using the sklearn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(type(iris))  # Print the type of the dataset object\n",
    "print(iris.feature_names)  # Print the names of the dataset's features\n",
    "print(iris.target_names)  # Print the names of the target classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris dataset is a collection of 150 labeled examples of Iris flowers, 50 of each type, described by these 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extract feature data (X) and target labels (y) from the Iris dataset\n",
    "# Features: Sepal length, sepal width, petal length, petal width\n",
    "X = iris.data\n",
    "# Target labels: Encoded as integers (0 = Setosa, 1 = Versicolor, 2 = Virginica)\n",
    "y = iris.target\n",
    "\n",
    "# Convert the feature data and target labels into a Pandas DataFrame\n",
    "df = pd.DataFrame(\n",
    "    data=X, columns=iris.feature_names\n",
    ")  # Create a DataFrame with feature names as column headers\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify its structure and content\n",
    "df.head()  # Returns the first 5 rows, including features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for human-readable class labels using the target names\n",
    "# Map the numerical target labels (0, 1, 2) to their corresponding class names (Setosa, Versicolor, Virginica)\n",
    "df[\"label\"] = pd.Series(iris.target_names[y], dtype=\"category\")\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify its structure and content\n",
    "df.head()  # Returns the first 5 rows, including features and their corresponding class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tabular data with a small number of features, it is common to make a `pair plot`, in which panel $(i, j)$ shows a scatter plot of variables $i$ and $j$, and the diagonal entries $(i,i)$ show the marginal density of variable $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom color palette to match the colors used in decision tree visualizations\n",
    "# The keys are the class names (labels), and the values are the colors assigned to each class\n",
    "palette = {\n",
    "    \"setosa\": \"orange\",  # Setosa class will be represented in orange\n",
    "    \"versicolor\": \"green\",  # Versicolor class will be represented in green\n",
    "    \"virginica\": \"purple\",  # Virginica class will be represented in purple\n",
    "}\n",
    "\n",
    "# Create a pair plot using Seaborn to visualize pairwise relationships between features\n",
    "# - `df`: The DataFrame containing the Iris dataset\n",
    "# - `vars`: Specifies the columns to use for the pair plot; in this case, the first 4 feature columns\n",
    "# - `hue`: Groups data points by the \"label\" column, which corresponds to the class labels\n",
    "# - `palette`: Applies the custom color mapping defined above for the classes\n",
    "g = sns.pairplot(df, vars=df.columns[0:4], hue=\"label\", palette=palette)\n",
    "\n",
    "# Display the resulting plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above demonstrates that Iris setosa is easily distinguishable due to its unique feature patterns. However, classifying Iris versicolor and Iris virginica is more difficult because their feature spaces overlap.\n",
    "\n",
    "To evaluate a classification model effectively, we divide the dataset into two subsets:\n",
    "\n",
    "- **Training Set**: Used to train the model.\n",
    "- **Testing (or Validation) Set**: Used to evaluate the model's performance on unseen data.\n",
    "\n",
    "This ensures that the model's performance is measured accurately and prevents overfitting. We’ll use the `train_test_split` function from `scikit-learn` to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from sklearn.naive_bayes import GaussianNB  # A classification algorithm (Naive Bayes)\n",
    "from sklearn.metrics import accuracy_score  # To measure the model's performance\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# - X: Feature matrix (sepal/petal dimensions for each Iris sample)\n",
    "# - y: Target labels (numerical representation of Iris species)\n",
    "# - test_size=0.2: 20% of the data is reserved for testing, and 80% for training\n",
    "# - random_state=42: Ensures reproducibility by using a fixed seed for randomness\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# The train_test_split function performs:\n",
    "# - Random shuffling of the dataset.\n",
    "# - Division of data into two parts: training set (X_train, y_train) and testing set (X_test, y_test).\n",
    "# - A specified proportion for the split (e.g., 80% training, 20% testing).\n",
    "\n",
    "# Print the shapes of the resulting datasets for verification\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "The Naive Bayes method is a probabilistic classifier based on Bayes' Theorem. It assumes that features are independent given the class label. Since the Iris dataset consists of continuous, real-valued features, we use the `Gaussian` Naive Bayes classifier, which assumes the feature values are normally distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.naive_bayes import GaussianNB  # Gaussian Naive Bayes classifier\n",
    "from sklearn.metrics import accuracy_score  # To evaluate model accuracy\n",
    "\n",
    "# Train a Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()  # Initialize the Gaussian Naive Bayes classifier\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "# - X_train: Feature matrix for training\n",
    "# - y_train: Target labels for training\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "# - X_test: Feature matrix for testing\n",
    "# - y_test: Target labels for testing\n",
    "y_pred = nb_classifier.predict(X_test)  # Predict the class labels for the test set\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Proportion of correct predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")  # Print accuracy as a percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll train the Gaussian Naive Bayes classifier on the Iris dataset, evaluate its performance using the training and testing sets, and then use 5-fold cross-validation to assess the model's accuracy across different splits of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Naive Bayes classifier (Gaussian Naive Bayes for this example)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation to evaluate the model's performance\n",
    "# - `cv=5`: Specifies 5-fold cross-validation\n",
    "cv_scores = cross_val_score(nb_classifier, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation scores for each fold\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Calculate and print the mean accuracy from cross-validation\n",
    "mean_accuracy = np.mean(cv_scores)  # Average accuracy across all folds\n",
    "print(\"Mean accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) Classifier\n",
    "\n",
    "Support Vector Machines (SVMs) are powerful classification models that find the optimal **hyperplane** to separate data points in a feature space. SVMs are particularly effective for binary classification, but they can also handle multi-class problems (like the Iris dataset) using extensions like one-vs-one or one-vs-rest strategies.Let's try the Naive Bayes method to classify the Iris flowers. \n",
    "\n",
    "### Understanding Kernels in SVMs\n",
    "Kernels are mathematical functions that transform data into a higher-dimensional space where a linear hyperplane can separate classes. The choice of kernel plays a critical role in the SVM's ability to handle different types of data:\n",
    "\n",
    "- Linear Kernel: Suitable for linearly separable data. It finds a straight hyperplane to separate the classes.\n",
    "- Polynomial Kernel: Useful when the data requires a polynomial decision boundary.\n",
    "- Radial Basis Function (RBF) Kernel (default): Often a good choice for non-linear data as it maps data to an infinite-dimensional space.\n",
    "- Sigmoid Kernel: Can handle sigmoid-like data distributions but is less commonly used.\n",
    "\n",
    "The choice of kernel depends on the nature of the data and the problem we are trying to solve. It's often a good idea to experiment with different kernels to find the one that works best for your specific dataset.\n",
    "\n",
    "For this example, we use the linear kernel, as it is computationally efficient and works well with the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  # Support Vector Classifier (SVM implementation)\n",
    "from sklearn.metrics import accuracy_score  # For evaluating the model's accuracy\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "# - `kernel=\"linear\"`: Specifies that we are using a linear kernel for this example\n",
    "svm_classifier_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# Train the SVM model on the training data\n",
    "# - `X_train`: Feature matrix for training\n",
    "# - `y_train`: Target labels for training\n",
    "svm_classifier_linear.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the trained model on the testing set\n",
    "# - `X_test`: Feature matrix for testing\n",
    "# - `y_test`: True target labels for testing\n",
    "y_pred = svm_classifier_linear.predict(X_test)  # Predict class labels for the test set\n",
    "\n",
    "# Calculate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Proportion of correct predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")  # Print accuracy as a percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 5-Fold Cross-Validation\n",
    "\n",
    "We will use 5-fold cross-validation to evaluate the accuracy of our SVM classifier. This approach divides our dataset into five subsets, trains the model on four subsets, and tests it on the remaining subset, repeating this process five times. This method helps us get a reliable estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Define the cross-validation method. We are using 5-fold cross-validation.\n",
    "# - `n_splits=5` specifies the number of folds.\n",
    "# - `shuffle=True` ensures that the data is shuffled before splitting into folds, which helps in achieving better generalization.\n",
    "# - `random_state=42` sets a fixed random seed for reproducibility, so that we get the same data splits every time we run the code.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "# - `svm_classifier` is our model (assumed to be predefined).\n",
    "# - `X` is the feature matrix (assumed to be predefined).\n",
    "# - `y` is the target vector (assumed to be predefined).\n",
    "# - `cv=kf` uses the KFold object we defined as the cross-validation strategy.\n",
    "cv_scores = cross_val_score(svm_classifier_linear, X, y, cv=kf)\n",
    "\n",
    "# Step 4: Print the cross-validation scores for each fold\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Step 4: Calculate and print the mean accuracy\n",
    "# - We use `np.mean` to compute the average of the cross-validation scores.\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "print(\"Mean accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate the performance of the default kernel, Radial Basis Function (RBF), for a Support Vector Classifier (SVC) using 5-fold cross-validation on the Iris dataset and compare it with the linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Define the cross-validation method using 5-fold cross-validation\n",
    "# - We reuse `kf` from the previous code block for consistency.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create an instance of the classifier\n",
    "# - `SVC()` creates a Support Vector Classifier with the default RBF kernel.\n",
    "svm_classifier_rbf = SVC()\n",
    "\n",
    "# Perform cross-validation and calculate the scores\n",
    "# - `classifier` is the model we want to evaluate.\n",
    "# - `X` is the feature matrix (assumed to be predefined).\n",
    "# - `y` is the target vector (assumed to be predefined).\n",
    "# - `cv=kf` uses the KFold object we defined as the cross-validation strategy.\n",
    "# - `scoring=\"accuracy\"` specifies that we want to evaluate the model based on accuracy.\n",
    "scores = cross_val_score(svm_classifier_rbf, X, y, cv=kf, scoring=\"accuracy\")\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "# Calculate and print the mean accuracy\n",
    "# - We use `np.mean` to compute the average of the cross-validation scores.\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(\"Mean accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Iris dataset, the linear kernel works better than the RBF kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST-784\n",
    "\n",
    "**MNIST-784** is a widely used dataset in the field of machine learning and computer vision. It stands for the \"Modified National Institute of Standards and Technology\" database. The MNIST dataset contains a large collection of handwritten digits (0 through 9), which are commonly used for training and testing machine learning models, especially for image classification tasks. Each image in the MNIST dataset is a grayscale image with a resolution of 28x28 pixels, resulting in 784 total pixels. These images are typically used to develop and test algorithms for digit recognition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# - `datasets` from `sklearn`: To fetch the MNIST dataset from OpenML.\n",
    "from sklearn import datasets\n",
    "\n",
    "# - `joblib`: To save and load the dataset locally for faster access in future runs.\n",
    "import joblib\n",
    "\n",
    "# - `Path` from `pathlib`: To handle file paths in a way that is compatible across different operating systems.\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the filename where the MNIST dataset will be saved locally.\n",
    "mnist_filename = \"./data/mnist_784.pkl\"\n",
    "\n",
    "# Create a Path object for the filename. This makes it easier to check if the file exists.\n",
    "path = Path(mnist_filename)\n",
    "\n",
    "# Check if the MNIST dataset file already exists locally.\n",
    "if not path.is_file():\n",
    "\n",
    "    # Create a directory named 'data'\n",
    "    # - `Path(\"data\")`: Creates a Path object for the 'data' directory.\n",
    "    # - `mkdir(parents=True, exist_ok=True)`: Creates the directory with specific conditions.\n",
    "    #   - `parents=True`: Ensures that any missing parent directories are also created.\n",
    "    #   - `exist_ok=True`: Prevents raising an error if the directory already exists.\n",
    "    Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # If the file does not exist, download the MNIST dataset from OpenML.\n",
    "    # - `fetch_openml(\"mnist_784\")`: Downloads the MNIST dataset.\n",
    "    # Note: This process will take about a minute.\n",
    "    mnist_dataset = datasets.fetch_openml(\"mnist_784\")\n",
    "\n",
    "    # Save the downloaded dataset to a local file using joblib.\n",
    "    joblib.dump(mnist_dataset, mnist_filename)\n",
    "\n",
    "# Load the MNIST dataset from the local file.\n",
    "mnist = joblib.load(mnist_filename)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y).\n",
    "# - `mnist.data`: Contains the pixel values of the images (features).\n",
    "# - `mnist.target`: Contains the corresponding digit labels (targets).\n",
    "features = mnist.data\n",
    "labels = mnist.target\n",
    "\n",
    "# Print information about the features.\n",
    "# - `features.info()`: Provides detailed information about the DataFrame, such as the number of entries, column data types, and memory usage.\n",
    "print(features.info())\n",
    "\n",
    "# Print information about the labels.\n",
    "# - `labels.info()`: Provides detailed information about the Series, such as the number of entries and memory usage.\n",
    "print(labels.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset includes a total of 70,000 handwritten digit images, spanning digits from 0 to 9. To get a better understanding of the dataset, we will visualize a subset of these entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the first few images from the dataset\n",
    "# - The dataset comprises 70,000 entries.\n",
    "# - We will reshape and display the first few images in a grid format.\n",
    "\n",
    "# Define the number of rows and columns in the grid\n",
    "# - `rows`: The number of rows in the grid.\n",
    "# - `cols`: The number of columns in the grid.\n",
    "# You can change these values to display more images.\n",
    "rows = 5  # Change this value to display more images\n",
    "cols = 10  # Change this value to display more images\n",
    "\n",
    "# Loop through each position in the grid\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        # Calculate the index of the current image\n",
    "        index = i * cols + j\n",
    "\n",
    "        # Extract the image data from the features DataFrame\n",
    "        # - `features.iloc[index]`: Selects the row at the specified index.\n",
    "        # - `to_numpy()`: Converts the row to a numpy array.\n",
    "        # - `reshape(28, 28)`: Reshapes the 1D array into a 2D array (28x28 pixels) to represent the image.\n",
    "        data = features.iloc[index]\n",
    "        image = data.to_numpy().reshape(28, 28)\n",
    "\n",
    "        # Create a subplot in the specified position\n",
    "        # - `plt.subplot(rows, cols, position)`: Creates a subplot in the specified grid position.\n",
    "        # The position is calculated as `i * cols + j + 1` because subplot positions start from 1.\n",
    "        plt.subplot(rows, cols, index + 1)\n",
    "\n",
    "        # Display the image\n",
    "        # - `plt.imshow(image, cmap=\"gray\")`: Displays the image in grayscale.\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "        # Set the title of the subplot to the corresponding label\n",
    "        # - `labels.iloc[index]`: Selects the label at the specified index.\n",
    "        plt.title(f\"{labels.iloc[index]}\")\n",
    "\n",
    "        # Turn off the axis\n",
    "        # - `plt.axis(\"off\")`: Hides the axis for a cleaner look.\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "# Show the grid of images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the features DataFrame\n",
    "# - `features.shape`: Returns the dimensions of the DataFrame as a tuple (number of rows, number of columns).\n",
    "# - This helps us understand the size of the dataset.\n",
    "print(features.shape)\n",
    "\n",
    "# Print the first few rows of the features DataFrame\n",
    "# - `features.head()`: Displays the first 5 rows of the DataFrame by default.\n",
    "# - This allows us to get a quick look at the structure and content of the dataset.\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the labels Series\n",
    "# - `labels.head()`: Displays the first 5 rows of the Series by default.\n",
    "# - This allows us to quickly see the first few labels (target values) in the dataset.\n",
    "print(labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 1\n",
    "\n",
    "We will use the Naive Bayes method to classify handwritten digits from the MNIST dataset. The first step is to normalize the pixel values to the range [0, 1]. For the MNIST dataset, which consists of grayscale pixel values ranging from 0 to 255, normalizing by dividing all pixel values by 255 is a straightforward way to achieve this. This normalization ensures that each pixel value is between 0 and 1, making the dataset more suitable for training machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the MNIST dataset\n",
    "# - `mnist.data`: Contains the pixel values of the images.\n",
    "# - `mnist.target`: Contains the corresponding digit labels.\n",
    "features = mnist.data\n",
    "labels = mnist.target\n",
    "\n",
    "# Preprocess the data\n",
    "# Normalize the pixel values to the range [0, 1]\n",
    "# - `features / 255.0`: Divides all pixel values by 255 to scale them to the range [0, 1].\n",
    "features_normalized = features / 255.0\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# - `train_test_split`: Splits the dataset into training and testing subsets.\n",
    "# - `features_normalized`: The normalized pixel values.\n",
    "# - `labels`: The corresponding digit labels.\n",
    "# - `test_size=0.2`: Specifies that 20% of the data should be used for testing, and 80% for training.\n",
    "# - `random_state=42`: Ensures reproducibility of the split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_normalized, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Output shapes for verification\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `Multinomial` Naive Bayes classifier because the dataset consists of discrete pixel values, where the features can be assumed to follow a multinomial distribution. This classifier is suitable for such data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Multinomial Naive Bayes classifier\n",
    "# - `MultinomialNB()`: Initializes the classifier.\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# TODO: Write your code for multinomial Naive Bayes that classifies the handwritten digits.\n",
    "# Ensure you print out the accuracy score.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Misclassified Digits\n",
    "We will use the index of misclassifications to display the first 10 misclassified digits from our model's predictions. Each displayed image will have the predicted label shown on top.\n",
    "\n",
    "**Steps**:\n",
    "1. Identify Misclassifications: Use the index of misclassifications where the predicted values differ from the true labels.\n",
    "1. Set Up Visualization: Use matplotlib to create a grid for displaying the misclassified images.\n",
    "1. Loop Through Misclassifications: Extract and display the first 10 misclassified images, adding the predicted values as titles, , as shown below.\n",
    "\n",
    "<div> <img src=\"./mnist_misclassifications.png\" width=\"600\"/> </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify misclassified indices\n",
    "# - `np.where(y_pred != y_test.values)[0]`: Finds the indices where the predicted labels differ from the true labels.\n",
    "# - `mis_indices_nb`: Stores the indices of misclassifications.\n",
    "mis_indices_nb = np.where(y_pred != y_test.values)[0]\n",
    "\n",
    "# Write your code to display the first 10 misclassified digits\n",
    "# - `num_images`: Number of misclassified images to display.\n",
    "num_images = 10  # Change this value to display more images\n",
    "\n",
    "# TODO: Write your code to display the first 10 misclassified digits.\n",
    "# You should add the predicted values on top of the digits.\n",
    "# To do this, use plt.title.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show the grid of misclassified images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 5-Fold Cross-Validation\n",
    "\n",
    "We will use 5-fold cross-validation to evaluate the accuracy of our Multinomial Naive Bayes classifier. This technique splits the dataset into five parts, trains the model on four parts, and tests it on the remaining part, repeating this process five times to get a robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Perform 5-fold cross-validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 2\n",
    "\n",
    "We will use the Support Vector Machine (SVM) method with a linear kernel to classify the handwritten digits from the MNIST dataset. The linear kernel is suitable for linearly separable data, assuming that the data can be separated by a straight line (hyperplane).\n",
    "\n",
    "Warning: It will take about 3-7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO: Write your code for SVM with linear kernel that classifies the handwritten digits.\n",
    "# Ensure you print out the accuracy score.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's experiment with the `Radial Basis Function (RBF) kernel`, which is a powerful choice for classification tasks, especially when the decision boundary is not expected to be linear or polynomial. It is highly versatile and can handle non-linear data effectively. Let's implement this and evaluate its performance.\n",
    "\n",
    "Warning: It will take about 3-7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO: Write your code for SVM with RBF kernel that classifies the handwritten digits.\n",
    "\n",
    "\n",
    "# Ensure you print out the accuracy score.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm whether the digits misclassified by the Naive Bayes classifier are now correctly classified by SVM. Display these misclassified digits along with their predicted values from SVM. To do this, use the same `mis_indices_nb` in conjunction with the `y_pred` from the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code to display the first 10 misclassified digits by Naive Bayes.\n",
    "# You should add the predicted values by SVM on top of the digits.\n",
    "\n",
    "# Reshape and display the first 10 misclassified digits by Naive Bayes\n",
    "# - `num_images`: Number of misclassified images to display.\n",
    "num_images = 10  # Change this value to display more images\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 5-fold cross-validation to find the accuracy scores and their average.\n",
    "\n",
    "We will use 5-fold cross-validation to evaluate the accuracy of our Support Vector Machine (SVM) classifier with the Radial Basis Function (RBF) kernel. This process will provide us with a reliable estimate of the model's performance.\n",
    "\n",
    "Warning: It will take about 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform 5-fold cross-validation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
