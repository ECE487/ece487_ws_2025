{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks \n",
    "\n",
    "- Author: Stan Baek  \n",
    "- Department of Electrical & Computer Engineering\n",
    "- United States Air Force Academy\n",
    "- Date: Aug 08, 2023  \n",
    "\n",
    "*2024-11-26: Comments heavily revised by Stan Baek*\n",
    "\n",
    "\n",
    "**A note on this document**\n",
    "This document is known as a Jupyter notebook; it allows text and executable code to coexist in a very easy-to-read format. Blocks can contain text or executable code. For blocks containing code, press `Shift + Enter`, `Ctrl+Enter`, or click the arrow on the block to run the code. Earlier blocks of code need to be run for the later blocks of code to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST-784\n",
    "\n",
    "MNIST-784 is a widely used dataset in the field of machine learning and computer vision. It stands for the \"Modified National Institute of Standards and Technology\" database. The MNIST dataset contains a large collection of handwritten digits (0 through 9), which are commonly used for training and testing machine learning models, especially for image classification tasks. Each image in the MNIST dataset is a grayscale image with a resolution of 28x28 pixels, resulting in 784 total pixels. These images are typically used to develop and test algorithms for digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the MNIST dataset\n",
    "\n",
    "mnist_filename = \"./data/mnist_784.pkl\"\n",
    "path = Path(mnist_filename)\n",
    "\n",
    "if not path.is_file():\n",
    "\n",
    "    Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # download the dataset. It will take about a minute.\n",
    "    mnist_dataset = datasets.fetch_openml(\"mnist_784\")\n",
    "    joblib.dump(mnist_dataset, mnist_filename)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = joblib.load(mnist_filename)\n",
    "\n",
    "# Split the data into features and labels\n",
    "features = mnist.data\n",
    "labels = mnist.target\n",
    "\n",
    "# features is a pandas.core.frame.DataFrame object\n",
    "print(features.info())\n",
    "\n",
    "# labels is a pandas.core.series.Series object\n",
    "print(labels.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated in the above information, the dataset comprises 70,000 entries. Let's display the first few entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape and display the first few images\n",
    "rows = 5  # Change this value to display more images\n",
    "cols = 10  # Change this value to display more images\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        data = features.iloc[i * cols + j]\n",
    "        image = data.to_numpy().reshape(28, 28)\n",
    "        plt.subplot(rows, cols, i * cols + j + 1)\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        plt.title(f\"{labels.iloc[i*cols+j]}\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features is a pandas.core.frame.DataFrame object\n",
    "print(features.shape)\n",
    "\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first step is to normalize the pixel values to the range [0, 1]. For the MNIST dataset, which consists of grayscale pixel values ranging from 0 to 255, normalizing by dividing all pixel values by 255 is a straightforward way to achieve this. This normalization ensures that each pixel value is between 0 and 1, making the dataset more suitable for training neural networks and other machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocess the data\n",
    "features_normalized = features / 255.0  # Normalize the pixel values to the range [0, 1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_normalized, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 2A\n",
    "\n",
    "Complete Deliverable 1 first and come back here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the SVM method to classify the handwritten digits. \n",
    "\n",
    "Use the `Radial Basis Function (RBF) kernel` to classify this dataset. The RBF kernel is a good choice when the decision boundary is not expected to be linear or polynomial. It is a versatile kernel for handling non-linear data.\n",
    "\n",
    "**You can copy and paste your Lab 7 code.**\n",
    "\n",
    "**Ensure you import necessary libraries**\n",
    "\n",
    "Warning: It will take about 3-7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code for SVM with RBF kernel that classifies the handwritten digits.\n",
    "# Ensure you print out the accuracy score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "file_path = \"lab8_svm_rbf_classifier.joblib\"\n",
    "\n",
    "# Save the object to a file\n",
    "joblib.dump(svm_rbf_classifier, file_path)\n",
    "\n",
    "# Load the object from the file\n",
    "svm_rbf_classifier = joblib.load(file_path)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm_rbf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following index of misclassification to display the misclassified digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_indices_svm = np.where(y_pred != y_test.values)[0]  # index of misclassification\n",
    "\n",
    "# TODO: Write your code to display the first 10 misclassified digits.\n",
    "# You should add the predicted values on top of the digits.\n",
    "# To do this, use plt.title.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 1\n",
    "\n",
    "Use `MLPClassifier` to classify the handwritten digits.\n",
    "\n",
    "Use the following parameters:\n",
    "\n",
    "- one hidden layer with 100 neurons. \n",
    "- sgd for the solver\n",
    "- random state = 1\n",
    "- default max iterations\n",
    "- default tolerance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Create an MLP Classifier\n",
    "# You may need to adjust the hyperparameters (hidden_layer_sizes, activation, etc.) based on your needs\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    max_iter=200,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 2B\n",
    "\n",
    "Complete Deliverable 2A and come back here.\n",
    "\n",
    "Let's confirm whether the digits misclassified by the SVM classifier are now correctly classified by NN. Display these misclassified digits along with their predicted values from NN. To do this, use the same `mis_indices_svm` in conjunction with the `y_pred` from the NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code to display the first 10 misclassified digits by Naive Bayes.\n",
    "# You should add the predicted values by SVM on top of the digits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 5-fold cross-validation to find the accuracy scores and their average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform 5-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 3\n",
    "\n",
    "Use different parameters for `MLPClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two hiddens layer with 100 neurons each. The rest are the same as Deliverable 1.\n",
    "\n",
    "# Create an MLP Classifier\n",
    "# You may need to adjust the hyperparameters (hidden_layer_sizes, activation, etc.) based on your needs\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 100),\n",
    "    max_iter=200,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function is sigmoid. The rest are the same as Deliverable 1.\n",
    "\n",
    "# Create an MLP Classifier\n",
    "# You may need to adjust the hyperparameters (hidden_layer_sizes, activation, etc.) based on your needs\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    max_iter=200,\n",
    "    activation=\"logistic\",\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate_init = default. The rest are the same as Deliverable 1.\n",
    "\n",
    "# Create an MLP Classifier\n",
    "# You may need to adjust the hyperparameters (hidden_layer_sizes, activation, etc.) based on your needs\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    max_iter=200,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tol is 1e-6. The rest are the same as Deliverable 1.\n",
    "\n",
    "# Create an MLP Classifier\n",
    "# You may need to adjust the hyperparameters (hidden_layer_sizes, activation, etc.) based on your needs\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    max_iter=200,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-6,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: `Discuss your findings in terms of the number of iterations, accuracy, computational time, and the final loss.`\n",
    "\n",
    "If you see the following message, click on `scrollable element`. \n",
    "\n",
    "```\n",
    "Output is truncated. View as a Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
